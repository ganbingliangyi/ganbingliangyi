{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6acfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee3b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "pad_left = 27\n",
    "pad_right = 27\n",
    "fine_size = 202\n",
    "batch_size = 18\n",
    "epoch = 300 \n",
    "snapshot = 6 \n",
    "max_lr = 0.012 \n",
    "min_lr = 0.001 \n",
    "momentum = 0.9 \n",
    "weight_decay = 1e-4 \n",
    "n_fold = 5\n",
    "device = torch.device('cuda')\n",
    "save_weight = 'weights/'\n",
    "if not os.path.isdir(save_weight):\n",
    "  os.mkdir(save_weight)\n",
    "weight_name = 'model_' + str(fine_size+pad_left+pad_right) + '_res18' \n",
    "\n",
    "train_image_dir = 'tgs-salt-identification-challenge/train/images'\n",
    "train_mask_dir = 'tgs-salt-identification-challenge/train/masks'\n",
    "test_image_dir = 'tgs-salt-identification-challenge/test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = pd.read_csv('tgs-salt-identification-challenge/depths.csv')\n",
    "depths.sort_values('z', inplace=True)\n",
    "depths.drop('z', axis=1, inplace=True)\n",
    "depths['fold'] = (list(range(0,5)) * depths.shape[0])[:depths.shape[0]]\n",
    "\n",
    "train_df = pd.read_csv('tgs-salt-identification-challenge/train.csv')\n",
    "train_df = train_df.merge(depths)\n",
    "dist = []\n",
    "for id in train_df.id.values:\n",
    "  img = cv2.imread(f'tgs-salt-identification-challenge/train/images/{id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "  dist.append(np.unique(img).shape[0])\n",
    "train_df['unique_pixels'] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainImageFetch(images_id):\n",
    "  image_train = np.zeros((images_id.shape[0], 101, 101), dtype=np.float32)\n",
    "  mask_train = np.zeros((images_id.shape[0], 101, 101), dtype=np.float32)\n",
    "\n",
    "  for idx, image_id in tqdm(enumerate(images_id), total=images_id.shape[0]):\n",
    "    image_path = os.path.join(train_image_dir, image_id+'.png')\n",
    "    mask_path = os.path.join(train_mask_dir, image_id+'.png')\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "\n",
    "    image_train[idx] = image\n",
    "    mask_train[idx] = mask\n",
    "  \n",
    "  return image_train, mask_train\n",
    "\n",
    "def testImageFetch(test_id):\n",
    "  image_test = np.zeros((len(test_id), 101, 101), dtype=np.float32)\n",
    "\n",
    "  for idx, image_id in tqdm(enumerate(test_id), total=len(test_id)):\n",
    "    image_path = os.path.join(test_image_dir, image_id+'.png')\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE).astype(np.float32) / 255\n",
    "    image_test[idx] = image\n",
    "\n",
    "  return image_test\n",
    "def do_resize2(image, mask, H, W):\n",
    "  image = cv2.resize(image, dsize=(W,H))\n",
    "  mask = cv2.resize(mask, dsize=(W,H))\n",
    "  return image, mask\n",
    "\n",
    "def do_center_pad(image, pad_left, pad_right):\n",
    "  return np.pad(image, (pad_left, pad_right), 'edge')\n",
    "\n",
    "def do_center_pad2(image, mask, pad_left, pad_right):\n",
    "  image = do_center_pad(image, pad_left, pad_right)\n",
    "  mask = do_center_pad(mask, pad_left, pad_right)\n",
    "  return image, mask\n",
    "\n",
    "class SaltDataset(Dataset):\n",
    "  def __init__(self, image_list, mode, mask_list=None, fine_size=202, pad_left=0, pad_right=0):\n",
    "    self.imagelist = image_list\n",
    "    self.mode = mode\n",
    "    self.masklist = mask_list\n",
    "    self.fine_size = fine_size\n",
    "    self.pad_left = pad_left\n",
    "    self.pad_right = pad_right\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imagelist)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = deepcopy(self.imagelist[idx])\n",
    "      if self.mode == 'train':\n",
    "      mask = deepcopy(self.masklist[idx])\n",
    "      label = np.where(mask.sum() == 0, 1.0, 0.0).astype(np.float32)\n",
    "\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image, mask = do_resize2(image, mask, self.fine_size, self.fine_size)\n",
    "\n",
    "      if self.pad_left != 0:\n",
    "        image, mask = do_center_pad2(image, mask, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "      mask = mask.reshape(1, mask.shape[0], mask.shape[1])    \n",
    "\n",
    "      return image, mask, label\n",
    "\n",
    "    elif self.mode == 'val':\n",
    "      mask = deepcopy(self.masklist[idx])\n",
    "\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image, mask = do_resize2(image, mask, self.fine_size, self.fine_size)\n",
    "\n",
    "      if self.pad_left != 0:\n",
    "        image = do_center_pad(image, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "      mask = mask.reshape(1, mask.shape[0], mask.shape[1])  \n",
    "\n",
    "      return image, mask\n",
    "\n",
    "    elif self.mode == 'test':\n",
    "      if self.fine_size != image.shape[0]:\n",
    "        image = cv2.resize(image, dsize=(self.fine_size, self.fine_size))\n",
    "        if self.pad_left != 0:\n",
    "        image = do_center_pad(image, self.pad_left, self.pad_right)\n",
    "\n",
    "      image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "\n",
    "      return image     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, in_channels, middle_channels, out_channels):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    self.conv_relu = nn.Sequential(\n",
    "        nn.Conv2d(middle_channels, out_channels, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "  def forward(self, x1, x2):\n",
    "    x1 = self.up(x1)\n",
    "    x1 = torch.cat((x1, x2), dim=1)\n",
    "    x1 = self.conv_relu(x1)\n",
    "    return x1\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = torchvision.models.resnet18(True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            self.base_layers[1],\n",
    "            self.base_layers[2])\n",
    "        self.layer2 = nn.Sequential(*self.base_layers[3:5])\n",
    "        self.layer3 = self.base_layers[5]\n",
    "        self.layer4 = self.base_layers[6]\n",
    "        self.layer5 = self.base_layers[7]\n",
    "        self.decode4 = Decoder(512, 256+256, 256)\n",
    "        self.decode3 = Decoder(256, 256+128, 256)\n",
    "        self.decode2 = Decoder(256, 128+64, 128)\n",
    "        self.decode1 = Decoder(128, 64+64, 64)\n",
    "        self.decode0 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "             nn.Conv2d(64, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False)\n",
    "            )\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        e1 = self.layer1(input) # 64,128,128\n",
    "        e2 = self.layer2(e1) # 64,64,64\n",
    "        e3 = self.layer3(e2) # 128,32,32\n",
    "        e4 = self.layer4(e3) # 256,16,16\n",
    "        f = self.layer5(e4) # 512,8,8\n",
    "        d4 = self.decode4(f, e4) # 256,16,16\n",
    "        d3 = self.decode3(d4, e3) # 256,32,32\n",
    "        d2 = self.decode2(d3, e2) # 128,64,64\n",
    "        d1 = self.decode1(d2, e1) # 64,128,128\n",
    "        d0 = self.decode0(d1) # 64,256,256\n",
    "        out = self.conv_last(d0) # 1,256,256\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(train_data)\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for inputs, masks, labels in train_loader:\n",
    "    inputs, masks, labels = inputs.to(device), masks.to(device), labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    with torch.set_grad_enabled(True):\n",
    "      logit = model(inputs)\n",
    "      loss = nn.BCEWithLogitsLoss()(logit.squeeze(1), masks.squeeze(1))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "  epoch_loss = running_loss / data_size\n",
    "  return epoch_loss\n",
    "\n",
    "def test(test_loader, model):\n",
    "  running_loss = 0.0\n",
    "  data_size = len(test_loader)\n",
    "  predicts = []\n",
    "  truths = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  for inputs, masks in test_loader:\n",
    "    inputs, masks = inputs.to(device), masks.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      outputs = model(inputs)\n",
    "      outputs = outputs[:, :, pad_left:pad_left + fine_size, pad_left:pad_left + fine_size].contiguous()\n",
    "      loss = nn.BCEWithLogitsLoss()(outputs.squeeze(1), masks.squeeze(1))\n",
    "\n",
    "    predicts.append(torch.sigmoid(outputs).detach().cpu().numpy()) \n",
    "    truths.append(masks.detach().cpu().numpy())\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "  predicts = np.concatenate(predicts).squeeze()\n",
    "  truths = np.concatenate(truths).squeeze()\n",
    "  precision, _, _ = do_kaggle_metric(predicts, truths, 0.5)\n",
    "  precision = precision.mean()\n",
    "  epoch_loss = running_loss / data_size\n",
    "  return epoch_loss, precision\n",
    "\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b079333",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = train_df['id'].values\n",
    "fold = []\n",
    "for i in range(5):\n",
    "  fold.append(train_df.loc[train_df['fold']==i, 'id'].values)\n",
    "\n",
    "salt = UNet(1)\n",
    "salt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(5):\n",
    "\n",
    "  if idx == 1:\n",
    "    break\n",
    "\n",
    "  # Setup optimizer\n",
    "  scheduler_step = epoch // snapshot\n",
    "  optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "\n",
    "  # Load data\n",
    "  train_id = np.setdiff1d(all_id, fold[idx])\n",
    "  val_id = fold[idx]\n",
    "\n",
    "  X_train, y_train = trainImageFetch(train_id)\n",
    "  X_val, y_val = trainImageFetch(val_id)\n",
    "\n",
    "  train_data = SaltDataset(X_train, 'train', y_train, pad_left=27, pad_right=27)\n",
    "  val_data = SaltDataset(X_val, 'val', y_val, pad_left=27, pad_right=27)\n",
    "\n",
    "  train_loader = DataLoader(train_data,\n",
    "                            shuffle=RandomSampler(train_data), \n",
    "                            batch_size=batch_size) \n",
    "\n",
    "  val_loader = DataLoader(val_data,\n",
    "                            shuffle=False, \n",
    "                            batch_size=batch_size) \n",
    "\n",
    "  num_snapshot = 0\n",
    "  best_acc = 0\n",
    " for epoch_ in range(epoch):\n",
    "    train_loss = train(train_loader, salt)\n",
    "    val_loss, accuracy = test(val_loader, salt)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "      best_acc = accuracy\n",
    "      best_param = salt.state_dict()\n",
    "\n",
    "    if (epoch_ + 1) % scheduler_step == 0:\n",
    "      torch.save(best_param, save_weight + weight_name + str(idx) + str(num_snapshot) + '.pth')\n",
    "      optimizer = torch.optim.SGD(salt.parameters(), lr=max_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "      lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, scheduler_step, min_lr)\n",
    "      num_snapshot += 1\n",
    "      best_acc = 0\n",
    "\n",
    "    print('epoch: {} train_loss: {:.3f} val_loss: {:.3f} val_accuracy: {:.3f}'.format(epoch_ + 1, train_loss, val_loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = [x[:-4] for x in os.listdir(test_image_dir) if x[-4:] == '.png']\n",
    "image_test = testImageFetch(test_id)\n",
    "overall_pred_101 = np.zeros((len(test_id), 101, 101), dtype=np.float32)\n",
    "\n",
    "for step in range(1, 6):\n",
    "\n",
    "  print('Predicting Snapshot', step)\n",
    "  pred_null = []\n",
    "\n",
    "  # Load weight\n",
    "  param = torch.load(save_weight + weight_name + '0' + str(step) + '.pth')\n",
    "  salt.load_state_dict(param)\n",
    "\n",
    "  # Dataloader\n",
    "  test_data = SaltDataset(image_test, mode='test', fine_size=fine_size, pad_left=pad_left, pad_right=pad_right)\n",
    "  test_loader = DataLoader(test_data,\n",
    "                            shuffle=False,\n",
    "                            batch_size=batch_size)\n",
    "  \n",
    "  # Prediction\n",
    "  salt.eval()\n",
    "  for images in tqdm(test_loader, total=len(test_loader)):\n",
    "    images = images.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "      pred = salt(images)\n",
    "      pred = torch.sigmoid(pred).squeeze(1).cpu().numpy()\n",
    "      pred = pred[:, pad_left:pad_left + fine_size, pad_left:pad_left + fine_size]\n",
    "      pred_null.append(pred)\n",
    "  \n",
    "  idx = 0\n",
    "  for i in range(len(pred_null)):\n",
    "    for j in range(batch_size):\n",
    "      overall_pred_101[idx] += cv2.resize(pred_null[i][j], dsize=(101, 101))\n",
    "      idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':test_id, 'rle_mask':list(overall_pred_101)})\n",
    "submission['rle_mask'] = submission['rle_mask'].map(lambda x: rle_encode(x>5*0.5))\n",
    "submission.set_index('id', inplace=True)\n",
    "\n",
    "sample_submission = pd.read_csv('tgs-salt-identification-challenge/sample_submission.csv')\n",
    "sample_submission.set_index('id', inplace=True)\n",
    "submission = submission.reindex(sample_submission.index)\n",
    "submission.reset_index(inplace=True)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
